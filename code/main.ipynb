{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import easydict\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "import warnings\n",
    "from glob import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append('informer')\n",
    "from inference import Predictor\n",
    "from informer.models.model import Informer\n",
    "from dataset import CustomDataset, load_data\n",
    "from utils import seed_everything\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"model\" : \"Informer\",\n",
    "    \"device\"    : torch.device(\"cuda:0\"),\n",
    "    \"input_window\" : 112,\n",
    "    \"target_window\" : 28,\n",
    "    \"label_len\" : 56,\n",
    "    \"target_n\"   : 21,\n",
    "    \"learning_rate\"  : 1e-3,                   \n",
    "    \"batch_size\"    : 128,                   \n",
    "    \"epochs\" : 100,               \n",
    "    \"path\" : \"../data/train.csv\",\n",
    "    \"inference_sample\" : \"../inference/sample_submission.csv\",\n",
    "    \"inference_sliced\" : \"../data/private/test/*.csv\",\n",
    "    'inference_result' : \"../inference/result.csv\",\n",
    "    \"save_path\"    : \"../models\",\n",
    "    \"use_best_model\": False,\n",
    "    \"enc_in\" : 2, # input feature dim,\n",
    "    \"dec_in\" : 1, # output feature dim\n",
    "    \"wandb\" : True,\n",
    "    \"randomseed\" : False\n",
    "})\n",
    "NAME_ELEMENTS = [args.model, str(args.learning_rate), str(args.batch_size), str(args.epochs), args.path.split('/')[-1].split('.')[0], time.strftime(\"%m%d_%H%M\", time.localtime(time.time()))]\n",
    "MODEL_NAME = '_'.join(NAME_ELEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.randomseed:\n",
    "    seed_everything(args.randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(pred, true, scaler):\n",
    "    pred = torch.from_numpy(scaler.inverse_transform(pred)).view(-1, 1)\n",
    "    true = torch.from_numpy(scaler.inverse_transform(true)).view(-1, 1)\n",
    "\n",
    "    score = torch.mean(torch.abs((true-pred))/(true))\n",
    "    #print(torch.mean(pred), torch.mean(true))\n",
    "    return score\n",
    "\n",
    "criterion = nn.L1Loss() # mae\n",
    "P = Predictor(args.inference_sample, args.inference_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstephencha\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/yai_timeseries/nongsanmul/runs/1wqhr691\" target=\"_blank\">Informer_0.001_128_100_train_1011_1422</a></strong> to <a href=\"https://wandb.ai/yai_timeseries/nongsanmul\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 배추\n",
      "Epoch:  1/100 | Validation loss: 0.737300\n",
      "        1/100 | Validation NMAE: 0.338758\n",
      "Validation NMAE decreased (inf --> 0.338758).  Saving model ...\n",
      "Epoch:  2/100 | Validation loss: 0.778890\n",
      "        2/100 | Validation NMAE: 0.320157\n",
      "Validation NMAE decreased (0.338758 --> 0.320157).  Saving model ...\n",
      "Epoch:  3/100 | Validation loss: 0.782489\n",
      "        3/100 | Validation NMAE: 0.390974\n",
      "Epoch:  4/100 | Validation loss: 0.752931\n",
      "        4/100 | Validation NMAE: 0.362006\n",
      "Epoch:  5/100 | Validation loss: 0.674865\n",
      "        5/100 | Validation NMAE: 0.264575\n",
      "Validation NMAE decreased (0.320157 --> 0.264575).  Saving model ...\n",
      "Epoch:  6/100 | Validation loss: 0.673730\n",
      "        6/100 | Validation NMAE: 0.276160\n",
      "Epoch:  7/100 | Validation loss: 0.669608\n",
      "        7/100 | Validation NMAE: 0.254289\n",
      "Validation NMAE decreased (0.264575 --> 0.254289).  Saving model ...\n",
      "Epoch:  8/100 | Validation loss: 0.659231\n",
      "        8/100 | Validation NMAE: 0.287046\n",
      "Epoch:  9/100 | Validation loss: 0.694915\n",
      "        9/100 | Validation NMAE: 0.346506\n",
      "Epoch: 10/100 | Validation loss: 0.692531\n",
      "       10/100 | Validation NMAE: 0.349405\n",
      "Epoch: 11/100 | Validation loss: 0.628361\n",
      "       11/100 | Validation NMAE: 0.277580\n",
      "Epoch: 12/100 | Validation loss: 0.639121\n",
      "       12/100 | Validation NMAE: 0.287014\n",
      "Epoch: 13/100 | Validation loss: 0.582762\n",
      "       13/100 | Validation NMAE: 0.257597\n",
      "Epoch: 14/100 | Validation loss: 0.606302\n",
      "       14/100 | Validation NMAE: 0.257962\n",
      "Epoch: 15/100 | Validation loss: 0.711057\n",
      "       15/100 | Validation NMAE: 0.347431\n",
      "Epoch: 16/100 | Validation loss: 0.578937\n",
      "       16/100 | Validation NMAE: 0.250042\n",
      "Validation NMAE decreased (0.254289 --> 0.250042).  Saving model ...\n",
      "Epoch: 17/100 | Validation loss: 0.601849\n",
      "       17/100 | Validation NMAE: 0.265511\n",
      "Epoch: 18/100 | Validation loss: 0.650051\n",
      "       18/100 | Validation NMAE: 0.324549\n",
      "Epoch: 19/100 | Validation loss: 0.532586\n",
      "       19/100 | Validation NMAE: 0.235518\n",
      "Validation NMAE decreased (0.250042 --> 0.235518).  Saving model ...\n",
      "Epoch: 20/100 | Validation loss: 0.533219\n",
      "       20/100 | Validation NMAE: 0.222915\n",
      "Validation NMAE decreased (0.235518 --> 0.222915).  Saving model ...\n",
      "Epoch: 21/100 | Validation loss: 0.543508\n",
      "       21/100 | Validation NMAE: 0.266646\n",
      "Epoch: 22/100 | Validation loss: 0.559678\n",
      "       22/100 | Validation NMAE: 0.264864\n",
      "Epoch: 23/100 | Validation loss: 0.566566\n",
      "       23/100 | Validation NMAE: 0.248772\n",
      "Epoch: 24/100 | Validation loss: 0.553650\n",
      "       24/100 | Validation NMAE: 0.252645\n",
      "Epoch: 25/100 | Validation loss: 0.497907\n",
      "       25/100 | Validation NMAE: 0.227215\n",
      "Epoch: 26/100 | Validation loss: 0.514766\n",
      "       26/100 | Validation NMAE: 0.228960\n",
      "Epoch: 27/100 | Validation loss: 0.484251\n",
      "       27/100 | Validation NMAE: 0.224057\n",
      "Epoch: 28/100 | Validation loss: 0.503979\n",
      "       28/100 | Validation NMAE: 0.233954\n",
      "Epoch: 29/100 | Validation loss: 0.520075\n",
      "       29/100 | Validation NMAE: 0.238514\n",
      "Epoch: 30/100 | Validation loss: 0.511797\n",
      "       30/100 | Validation NMAE: 0.236591\n",
      "Epoch: 31/100 | Validation loss: 0.555315\n",
      "       31/100 | Validation NMAE: 0.236560\n",
      "Epoch: 32/100 | Validation loss: 0.629917\n",
      "       32/100 | Validation NMAE: 0.312212\n",
      "Epoch: 33/100 | Validation loss: 0.615561\n",
      "       33/100 | Validation NMAE: 0.323271\n",
      "Epoch: 34/100 | Validation loss: 0.567300\n",
      "       34/100 | Validation NMAE: 0.241093\n",
      "Epoch: 35/100 | Validation loss: 0.670961\n",
      "       35/100 | Validation NMAE: 0.312942\n",
      "Epoch: 36/100 | Validation loss: 0.636933\n",
      "       36/100 | Validation NMAE: 0.274897\n",
      "Epoch: 37/100 | Validation loss: 0.531614\n",
      "       37/100 | Validation NMAE: 0.227030\n",
      "Epoch: 38/100 | Validation loss: 0.593728\n",
      "       38/100 | Validation NMAE: 0.289214\n",
      "Epoch: 39/100 | Validation loss: 0.580639\n",
      "       39/100 | Validation NMAE: 0.270299\n",
      "Epoch: 40/100 | Validation loss: 0.535771\n",
      "       40/100 | Validation NMAE: 0.231406\n",
      "Epoch: 41/100 | Validation loss: 0.629977\n",
      "       41/100 | Validation NMAE: 0.310124\n",
      "Epoch: 42/100 | Validation loss: 0.554706\n",
      "       42/100 | Validation NMAE: 0.243016\n",
      "Epoch: 43/100 | Validation loss: 0.624030\n",
      "       43/100 | Validation NMAE: 0.312892\n",
      "Epoch: 44/100 | Validation loss: 0.609703\n",
      "       44/100 | Validation NMAE: 0.298495\n",
      "Epoch: 45/100 | Validation loss: 0.588449\n",
      "       45/100 | Validation NMAE: 0.276419\n",
      "Epoch: 46/100 | Validation loss: 0.592336\n",
      "       46/100 | Validation NMAE: 0.253645\n",
      "Epoch: 47/100 | Validation loss: 0.589109\n",
      "       47/100 | Validation NMAE: 0.258446\n",
      "Epoch: 48/100 | Validation loss: 0.645063\n",
      "       48/100 | Validation NMAE: 0.287448\n",
      "Epoch: 49/100 | Validation loss: 0.608056\n",
      "       49/100 | Validation NMAE: 0.283311\n",
      "Epoch: 50/100 | Validation loss: 0.604075\n",
      "       50/100 | Validation NMAE: 0.264544\n",
      "Epoch: 51/100 | Validation loss: 0.532970\n",
      "       51/100 | Validation NMAE: 0.231523\n",
      "Epoch: 52/100 | Validation loss: 0.584741\n",
      "       52/100 | Validation NMAE: 0.256182\n",
      "Epoch: 53/100 | Validation loss: 0.569809\n",
      "       53/100 | Validation NMAE: 0.250007\n",
      "Epoch: 54/100 | Validation loss: 0.550618\n",
      "       54/100 | Validation NMAE: 0.237878\n",
      "Epoch: 55/100 | Validation loss: 0.552699\n",
      "       55/100 | Validation NMAE: 0.252871\n",
      "Epoch: 56/100 | Validation loss: 0.550568\n",
      "       56/100 | Validation NMAE: 0.248819\n",
      "Epoch: 57/100 | Validation loss: 0.541158\n",
      "       57/100 | Validation NMAE: 0.246235\n",
      "Epoch: 58/100 | Validation loss: 0.560796\n",
      "       58/100 | Validation NMAE: 0.252886\n",
      "Epoch: 59/100 | Validation loss: 0.545685\n",
      "       59/100 | Validation NMAE: 0.244841\n",
      "Epoch: 60/100 | Validation loss: 0.546570\n",
      "       60/100 | Validation NMAE: 0.239761\n",
      "Epoch: 61/100 | Validation loss: 0.584003\n",
      "       61/100 | Validation NMAE: 0.262613\n",
      "Epoch: 62/100 | Validation loss: 0.587545\n",
      "       62/100 | Validation NMAE: 0.257286\n",
      "Epoch: 63/100 | Validation loss: 0.571525\n",
      "       63/100 | Validation NMAE: 0.246756\n",
      "Epoch: 64/100 | Validation loss: 0.567562\n",
      "       64/100 | Validation NMAE: 0.252788\n",
      "Epoch: 65/100 | Validation loss: 0.559108\n",
      "       65/100 | Validation NMAE: 0.246353\n",
      "Epoch: 66/100 | Validation loss: 0.563005\n",
      "       66/100 | Validation NMAE: 0.254195\n",
      "Epoch: 67/100 | Validation loss: 0.570467\n",
      "       67/100 | Validation NMAE: 0.250050\n",
      "Epoch: 68/100 | Validation loss: 0.580320\n",
      "       68/100 | Validation NMAE: 0.250347\n",
      "Epoch: 69/100 | Validation loss: 0.550716\n",
      "       69/100 | Validation NMAE: 0.248553\n",
      "Epoch: 70/100 | Validation loss: 0.571751\n",
      "       70/100 | Validation NMAE: 0.249842\n",
      "Epoch: 71/100 | Validation loss: 0.587138\n",
      "       71/100 | Validation NMAE: 0.261864\n",
      "Epoch: 72/100 | Validation loss: 0.591469\n",
      "       72/100 | Validation NMAE: 0.285119\n",
      "Epoch: 73/100 | Validation loss: 0.559659\n",
      "       73/100 | Validation NMAE: 0.268155\n",
      "Epoch: 74/100 | Validation loss: 0.563226\n",
      "       74/100 | Validation NMAE: 0.254196\n",
      "Epoch: 75/100 | Validation loss: 0.637912\n",
      "       75/100 | Validation NMAE: 0.305646\n",
      "Epoch: 76/100 | Validation loss: 0.604628\n",
      "       76/100 | Validation NMAE: 0.266569\n",
      "Epoch: 77/100 | Validation loss: 0.581838\n",
      "       77/100 | Validation NMAE: 0.257545\n",
      "Epoch: 78/100 | Validation loss: 0.657083\n",
      "       78/100 | Validation NMAE: 0.346274\n",
      "Epoch: 79/100 | Validation loss: 0.536547\n",
      "       79/100 | Validation NMAE: 0.256940\n",
      "Epoch: 80/100 | Validation loss: 0.557048\n",
      "       80/100 | Validation NMAE: 0.244662\n",
      "Epoch: 81/100 | Validation loss: 0.658138\n",
      "       81/100 | Validation NMAE: 0.309272\n",
      "Epoch: 82/100 | Validation loss: 0.605639\n",
      "       82/100 | Validation NMAE: 0.288612\n",
      "Epoch: 83/100 | Validation loss: 0.644057\n",
      "       83/100 | Validation NMAE: 0.303957\n",
      "Epoch: 84/100 | Validation loss: 0.593167\n",
      "       84/100 | Validation NMAE: 0.268300\n",
      "Epoch: 85/100 | Validation loss: 0.595701\n",
      "       85/100 | Validation NMAE: 0.273614\n",
      "Epoch: 86/100 | Validation loss: 0.616014\n",
      "       86/100 | Validation NMAE: 0.274711\n",
      "Epoch: 87/100 | Validation loss: 0.550635\n",
      "       87/100 | Validation NMAE: 0.246276\n",
      "Epoch: 88/100 | Validation loss: 0.616130\n",
      "       88/100 | Validation NMAE: 0.279873\n",
      "Epoch: 89/100 | Validation loss: 0.579591\n",
      "       89/100 | Validation NMAE: 0.277781\n",
      "Epoch: 90/100 | Validation loss: 0.589678\n",
      "       90/100 | Validation NMAE: 0.262527\n",
      "Epoch: 91/100 | Validation loss: 0.613680\n",
      "       91/100 | Validation NMAE: 0.280246\n",
      "Epoch: 92/100 | Validation loss: 0.602043\n",
      "       92/100 | Validation NMAE: 0.267950\n",
      "Epoch: 93/100 | Validation loss: 0.526834\n",
      "       93/100 | Validation NMAE: 0.240464\n"
     ]
    }
   ],
   "source": [
    "breed_list = [\n",
    "        '배추', '무', '양파', '건고추','마늘',\n",
    "        '대파', '얼갈이배추', '양배추', '깻잎',\n",
    "        '시금치', '미나리', '당근',\n",
    "        '파프리카', '새송이', '팽이버섯', '토마토',\n",
    "        '청상추', '백다다기', '애호박', '캠벨얼리', '샤인마스캇'\n",
    "    ]\n",
    "    \n",
    "if args.wandb:\n",
    "    run = wandb.init(entity=\"yai_timeseries\", project=\"nongsanmul\", name=MODEL_NAME, config=args, reinit=True)\n",
    "for breed in breed_list:\n",
    "    model = Informer(\n",
    "                enc_in=args.enc_in, \n",
    "                dec_in=args.dec_in, \n",
    "                c_out= 1,\n",
    "                out_len=args.target_window,\n",
    "                ).to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                                                                optimizer, \n",
    "                                                                T_0=10, \n",
    "                                                                T_mult=2, \n",
    "                                                                eta_min=1e-7\n",
    "                                                                )\n",
    "                                                                \n",
    "    train_loader, valid_loader, dataset = load_data(\n",
    "                                                    args.path, \n",
    "                                                    breed, \n",
    "                                                    args.input_window, \n",
    "                                                    args.target_window, \n",
    "                                                    args.label_len, \n",
    "                                                    batch_size=args.batch_size\n",
    "                                                    )\n",
    "    price_scaler = dataset.std_scaler\n",
    "    volume_scaler = dataset.std_scaler_volume\n",
    "    if not os.path.exists(os.path.join(args.save_path, breed)):\n",
    "        os.makedirs(os.path.join(args.save_path, breed), exist_ok=True)\n",
    "    ### Training\n",
    "    best_nmae = np.Inf\n",
    "    print(\"Training :\", breed)\n",
    "    for epoch in range(args.epochs):\n",
    "        ### Training\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_nmae = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            price = data['price_std'].unsqueeze(2)\n",
    "            volume = data['volume_std'].unsqueeze(2)\n",
    "            x_mark = data['x_mark'].permute(0, 2, 1).to(args.device)\n",
    "            y_mark = data['y_mark'].permute(0, 2, 1).to(args.device)\n",
    "            y = data['y'].unsqueeze(2)\n",
    "            gt = y[:, -args.target_window:, :].to(args.device)\n",
    "\n",
    "            x = torch.cat([price, volume], dim=2).to(args.device)\n",
    "            dec_inp = torch.zeros([y.shape[0], args.target_window, 1])\n",
    "\n",
    "            y = torch.cat([y[:, :args.label_len, :], dec_inp], dim=1).to(args.device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x, x_mark, y, y_mark)\n",
    "            \n",
    "\n",
    "            gt = gt[:, [6, 13, 27], :]\n",
    "            outputs = outputs[:, [6, 13, 27], :]\n",
    "\n",
    "            loss = criterion(outputs, gt)\n",
    "            score = nmae(outputs.detach().cpu(), gt.detach().cpu(), price_scaler)\n",
    "\n",
    "            train_nmae.append(score)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_nmae = np.mean(train_nmae)\n",
    "\n",
    "        ### Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_nmae = []\n",
    "            for i, data in enumerate(valid_loader):\n",
    "                price = data['price_std'].unsqueeze(2)\n",
    "                volume = data['volume_std'].unsqueeze(2)\n",
    "                x_mark = data['x_mark'].permute(0, 2, 1).to(args.device)\n",
    "                y_mark = data['y_mark'].permute(0, 2, 1).to(args.device)\n",
    "                y = data['y'].unsqueeze(2)\n",
    "                gt = y[:, -args.target_window:, :].to(args.device)\n",
    "\n",
    "                x = torch.cat([price, volume], dim=2).to(args.device)\n",
    "                dec_inp = torch.zeros([y.shape[0], args.target_window, 1])\n",
    "\n",
    "                y = torch.cat([y[:, :args.label_len, :], dec_inp], dim=1).to(args.device)\n",
    "                \n",
    "                outputs = model(x, x_mark, y, y_mark)\n",
    "\n",
    "                gt = gt[:, [6, 13, 27], :]\n",
    "                outputs = outputs[:, [6, 13, 27], :]\n",
    "                #\n",
    "                loss = criterion(outputs, gt)\n",
    "                score = nmae(outputs.detach().cpu(), gt.detach().cpu(), price_scaler)\n",
    "                \n",
    "                val_nmae.append(score)\n",
    "                val_loss.append(loss.item())\n",
    "            val_nmae = np.mean(val_nmae)\n",
    "            val_loss = np.mean(val_loss)\n",
    "            print(\"Epoch: {:>2}/{} | Validation loss: {:.6f}\".format(epoch+1, args.epochs, val_loss))\n",
    "            print(\"       {:>2}/{} | Validation NMAE: {:.6f}\".format(epoch+1, args.epochs, val_nmae))\n",
    "            if val_nmae < best_nmae:\n",
    "                print(f'Validation NMAE decreased ({best_nmae:.6f} --> {val_nmae:.6f}).  Saving model ...')\n",
    "                path_dir = [args.save_path, breed, '{:.6f}.pt'.format(val_nmae)]\n",
    "                torch.save(model.state_dict(), os.path.join(*path_dir))\n",
    "                best_nmae = val_nmae\n",
    "        if args.wandb:\n",
    "            wandb.log({\n",
    "                breed+\"/Train/Loss\" : train_loss,\n",
    "                breed+\"/Train/NMAE\" : train_nmae,\n",
    "                breed+\"/Val/Loss\" : val_loss,\n",
    "                breed+\"/Val/NMAE\" : val_nmae\n",
    "            })\n",
    "        scheduler.step()\n",
    "    print(\"Loading Best Model\")\n",
    "    best_model_dir = [args.save_path, breed, '{:.6f}.pt'.format(best_nmae)]\n",
    "    model.load_state_dict(torch.load(os.path.join(*best_model_dir)))\n",
    "\n",
    "    print(\"Inference :\", breed)\n",
    "    P.get_dataset(args, breed, price_scaler, volume_scaler)\n",
    "    P.predict(args, model, breed, args.inference_result)\n",
    "if args.wandb:\n",
    "    run.finish()\n",
    "print(\"Done!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import scoring\n",
    "import pandas as pd\n",
    "\n",
    "ANSWER_PATH = \"../data/public_test.csv\"\n",
    "answer_df = pd.read_csv(ANSWER_PATH)\n",
    "submission_df = pd.read_csv(args.inference_result)\n",
    "print(\"Score: {}\".format(scoring(answer_df, submission_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
