{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import easydict\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "import warnings\n",
    "from glob import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append('informer')\n",
    "from inference import Predictor\n",
    "from informer.models.model import Informer\n",
    "from dataset import CustomDataset, load_data\n",
    "from utils import seed_everything\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"model\" : \"Informer\",\n",
    "    \"device\"    : torch.device(\"cuda:0\"),\n",
    "    \"input_window\" : 112,\n",
    "    \"target_window\" : 28,\n",
    "    \"label_len\" : 56,\n",
    "    \"target_n\"   : 21,\n",
    "    \"learning_rate\"  : 1e-3,                   \n",
    "    \"batch_size\"    : 128,                   \n",
    "    \"epochs\" : 100,               \n",
    "    \"path\" : \"../data/train.csv\",\n",
    "    \"inference_sample\" : \"../inference/sample_submission.csv\",\n",
    "    \"inference_sliced\" : \"../data/private/test/*.csv\",\n",
    "    'inference_result' : \"../inference/result.csv\",\n",
    "    \"save_path\"    : \"../models\",\n",
    "    \"use_best_model\": False,\n",
    "    \"enc_in\" : 2, # input feature dim,\n",
    "    \"dec_in\" : 1, # output feature dim\n",
    "    \"wandb\" : True,\n",
    "    \"randomseed\" : False\n",
    "})\n",
    "NAME_ELEMENTS = [args.model, str(args.learning_rate), str(args.batch_size), str(args.epochs), args.path.split('/')[-1].split('.')[0], time.strftime(\"%m%d_%H%M\", time.localtime(time.time()))]\n",
    "MODEL_NAME = '_'.join(NAME_ELEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.randomseed:\n",
    "    seed_everything(args.randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(pred, true, scaler):\n",
    "    pred = torch.from_numpy(scaler.inverse_transform(pred)).view(-1, 1)\n",
    "    true = torch.from_numpy(scaler.inverse_transform(true)).view(-1, 1)\n",
    "\n",
    "    score = torch.mean(torch.abs((true-pred))/(true))\n",
    "    #print(torch.mean(pred), torch.mean(true))\n",
    "    return score\n",
    "\n",
    "criterion = nn.L1Loss() # mae\n",
    "P = Predictor(args.inference_sample, args.inference_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myai_timeseries\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Informer_0.001_128_100_train_0930_2120</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/yai_timeseries/nongsanmul\" target=\"_blank\">https://wandb.ai/yai_timeseries/nongsanmul</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/yai_timeseries/nongsanmul/runs/117l9dvb\" target=\"_blank\">https://wandb.ai/yai_timeseries/nongsanmul/runs/117l9dvb</a><br/>\n",
       "                Run data is saved locally in <code>/home/stephencha/Lab/202109 농산물 가격예측 AI 경진대회/nongsanmul/code/wandb/run-20210930_212052-117l9dvb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 배추\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "Epoch:  1/100 | Validation loss: 0.883344\n",
      "        1/100 | Validation NMAE: 0.319189\n",
      "Validation NMAE decreased (inf --> 0.319189).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "Epoch:  2/100 | Validation loss: 0.775999\n",
      "        2/100 | Validation NMAE: 0.321875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "torch.Size([128, 28, 1])\n",
      "Epoch:  3/100 | Validation loss: 0.907240\n",
      "        3/100 | Validation NMAE: 0.340648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_990848/1177698198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtrain_nmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_nmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "breed_list = [\n",
    "        '배추', '무', '양파', '건고추','마늘',\n",
    "        '대파', '얼갈이배추', '양배추', '깻잎',\n",
    "        '시금치', '미나리', '당근',\n",
    "        '파프리카', '새송이', '팽이버섯', '토마토',\n",
    "        '청상추', '백다다기', '애호박', '캠벨얼리', '샤인마스캇'\n",
    "    ]\n",
    "    \n",
    "if args.wandb:\n",
    "    run = wandb.init(entity=\"yai_timeseries\", project=\"nongsanmul\", name=MODEL_NAME, config=args, reinit=True)\n",
    "for breed in breed_list:\n",
    "    model = Informer(\n",
    "                enc_in=args.enc_in, \n",
    "                dec_in=args.dec_in, \n",
    "                c_out= 1,\n",
    "                out_len=args.target_window,\n",
    "                ).to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                                                                optimizer, \n",
    "                                                                T_0=10, \n",
    "                                                                T_mult=2, \n",
    "                                                                eta_min=1e-7\n",
    "                                                                )\n",
    "                                                                \n",
    "    train_loader, valid_loader, dataset = load_data(\n",
    "                                                    args.path, \n",
    "                                                    breed, \n",
    "                                                    args.input_window, \n",
    "                                                    args.target_window, \n",
    "                                                    args.label_len, \n",
    "                                                    batch_size=args.batch_size\n",
    "                                                    )\n",
    "    price_scaler = dataset.std_scaler\n",
    "    volume_scaler = dataset.std_scaler_volume\n",
    "    if not os.path.exists(os.path.join(args.save_path, breed)):\n",
    "        os.makedirs(os.path.join(args.save_path, breed), exist_ok=True)\n",
    "    ### Training\n",
    "    best_nmae = np.Inf\n",
    "    print(\"Training :\", breed)\n",
    "    for epoch in range(args.epochs):\n",
    "        ### Training\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_nmae = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            price = data['price_std'].unsqueeze(2)\n",
    "            volume = data['volume_std'].unsqueeze(2)\n",
    "            x_mark = data['x_mark'].permute(0, 2, 1).to(args.device)\n",
    "            y_mark = data['y_mark'].permute(0, 2, 1).to(args.device)\n",
    "            y = data['y'].unsqueeze(2)\n",
    "            gt = y[:, -args.target_window:, :].to(args.device)\n",
    "\n",
    "            x = torch.cat([price, volume], dim=2).to(args.device)\n",
    "            dec_inp = torch.zeros([y.shape[0], args.target_window, 1])\n",
    "\n",
    "            y = torch.cat([y[:, :args.label_len, :], dec_inp], dim=1).to(args.device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x, x_mark, y, y_mark)\n",
    "            \n",
    "\n",
    "            gt = gt[:, [6, 13, 27], :]\n",
    "            outputs = outputs[:, [6, 13, 27], :]\n",
    "\n",
    "            loss = criterion(outputs, gt)\n",
    "            score = nmae(outputs.detach().cpu(), gt.detach().cpu(), price_scaler)\n",
    "\n",
    "            train_nmae.append(score)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_nmae = np.mean(train_nmae)\n",
    "\n",
    "        ### Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_nmae = []\n",
    "            for i, data in enumerate(valid_loader):\n",
    "                price = data['price_std'].unsqueeze(2)\n",
    "                volume = data['volume_std'].unsqueeze(2)\n",
    "                x_mark = data['x_mark'].permute(0, 2, 1).to(args.device)\n",
    "                y_mark = data['y_mark'].permute(0, 2, 1).to(args.device)\n",
    "                y = data['y'].unsqueeze(2)\n",
    "                gt = y[:, -args.target_window:, :].to(args.device)\n",
    "\n",
    "                x = torch.cat([price, volume], dim=2).to(args.device)\n",
    "                dec_inp = torch.zeros([y.shape[0], args.target_window, 1])\n",
    "\n",
    "                y = torch.cat([y[:, :args.label_len, :], dec_inp], dim=1).to(args.device)\n",
    "                \n",
    "                outputs = model(x, x_mark, y, y_mark)\n",
    "\n",
    "                gt = gt[:, [6, 13, 27], :]\n",
    "                outputs = outputs[:, [6, 13, 27], :]\n",
    "                #\n",
    "                loss = criterion(outputs, gt)\n",
    "                score = nmae(outputs.detach().cpu(), gt.detach().cpu(), price_scaler)\n",
    "                \n",
    "                val_nmae.append(score)\n",
    "                val_loss.append(loss.item())\n",
    "            val_nmae = np.mean(val_nmae)\n",
    "            val_loss = np.mean(val_loss)\n",
    "            print(\"Epoch: {:>2}/{} | Validation loss: {:.6f}\".format(epoch+1, args.epochs, val_loss))\n",
    "            print(\"       {:>2}/{} | Validation NMAE: {:.6f}\".format(epoch+1, args.epochs, val_nmae))\n",
    "            if val_nmae < best_nmae:\n",
    "                print(f'Validation NMAE decreased ({best_nmae:.6f} --> {val_nmae:.6f}).  Saving model ...')\n",
    "                path_dir = [args.save_path, breed, '{:.6f}.pt'.format(val_nmae)]\n",
    "                torch.save(model.state_dict(), os.path.join(*path_dir))\n",
    "                best_nmae = val_nmae\n",
    "        if args.wandb:\n",
    "            wandb.log({\n",
    "                breed+\"/Train/Loss\" : train_loss,\n",
    "                breed+\"/Train/NMAE\" : train_nmae,\n",
    "                breed+\"/Val/Loss\" : val_loss,\n",
    "                breed+\"/Val/NMAE\" : val_nmae\n",
    "            })\n",
    "        scheduler.step()\n",
    "    print(\"Loading Best Model\")\n",
    "    best_model_dir = [args.save_path, breed, '{:.6f}.pt'.format(best_nmae)]\n",
    "    model.load_state_dict(torch.load(os.path.join(*best_model_dir)))\n",
    "\n",
    "    print(\"Inference :\", breed)\n",
    "    P.get_dataset(args, breed, price_scaler, volume_scaler)\n",
    "    P.predict(args, model, breed, args.inference_result)\n",
    "if args.wandb:\n",
    "    run.finish()\n",
    "print(\"Done!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import scoring\n",
    "import pandas as pd\n",
    "\n",
    "ANSWER_PATH = \"../data/public_test.csv\"\n",
    "answer_df = pd.read_csv(ANSWER_PATH)\n",
    "submission_df = pd.read_csv(args.inference_result)\n",
    "print(\"Score: {}\".format(scoring(answer_df, submission_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
